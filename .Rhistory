sa_policy = dataTopredict[j,3]
saGDP = dataTopredict[j,4]
y = glsDATA[1,1] + glsDATA[2,1]*us_long_term+ glsDATA[3,1]*saGDP+
glsDATA[4,1]*sa_head_cpi + glsDATA[5,1]*sa_policy
list_ofY <- c(list_ofY, y)
}
startPos = startPos+1
stopPos = stopPos+1
output[paste(startYear, cunt ,sep = '.')] <- list_ofY
francis <- data.frame(
R2 = rsquare(GLSroll, data=ts_data1),
RMSE = rmse(GLSroll, data=ts_data1),
MAE = mae(GLSroll, data=ts_data1)
)
outputResidualsForGLS[paste(startYear,cunt,sep = '.')] <- t(francis)
##update the while loop[]
i = i+1
cunt = cunt +1
if( cunt %% 4 == 0){
n=n+1
}
}
i = 61
n = 0
startPos = 12
stopPos = 19
##count to mod by 4
cunt = 0
while ( i < 105 && n <15 && startPos <= 157){
startYear = 1980+n
endYear = 2007+n
#the time series obejct
ts_data1 <- ts(fairValue[i:216,], start= startYear, end = c(endYear, 4), frequency = 4)
##The variables
us_long = ts_data1[,1]
sa_headline_cpi = ts_data1[,2]
sa_st_policy = ts_data1[,3]
sa_dGDP = ts_data1[,4]
sa_long = ts_data1[,5]
modbind = cbind(us_long, sa_headline_cpi, sa_st_policy, sa_dGDP, sa_long)
#the gls model
GLSroll = gls(sa_long ~ us_long+sa_dGDP+sa_headline_cpi+sa_st_policy,
correlation = corAR1())
summ = summary(GLSroll)
##store coefficients to a dataframe
coefs[paste(startYear,cunt,sep = '.')]  <- as.data.frame(summ$coefficients)
#print(paste('startYear',paste(startYear, cunt) ,sep = ': '))
##output the predicted variables to a dataframe
glsDATA = as.data.frame(summ$coefficients)
list_ofY <- c()
##predict 2018 - now)
print(dataTopredict[startPos,])
for(j in startPos:stopPos){
us_long_term = dataTopredict[j,1]
sa_head_cpi = dataTopredict[j,2]
sa_policy = dataTopredict[j,3]
saGDP = dataTopredict[j,4]
y = glsDATA[1,1] + glsDATA[2,1]*us_long_term+ glsDATA[3,1]*saGDP+
glsDATA[4,1]*sa_head_cpi + glsDATA[5,1]*sa_policy
list_ofY <- c(list_ofY, y)
}
startPos = startPos+1
stopPos = stopPos+1
output[paste(startYear, cunt ,sep = '.')] <- list_ofY
francis <- data.frame(
R2 = rsquare(GLSroll, data=ts_data1),
RMSE = rmse(GLSroll, data=ts_data1),
MAE = mae(GLSroll, data=ts_data1)
)
outputResidualsForGLS[paste(startYear,cunt,sep = '.')] <- t(francis)
##update the while loop[]
i = i+1
cunt = cunt +1
if( cunt %% 4 == 0){
n=n+1
}
}
warnings()
View(coefs)
check.packages('xlsx')
check.packages('xlsx')
install.packages("rJava")
check.packages('xlsx')
check.packages('rJava')
install.packages("rJava")
library('rJava')
library("rJava", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
detach("package:rJava", unload=TRUE)
#package to load packages
check.packages <- function(pkg) {
new.pkg <- pkg[! (pkg %in% installed.packages()[, 'Package'])]
if(length(new.pkg))
install.packages(new.pkg, dependencies = T)
sapply(pkg, require, character.only = T)
}
rm(list = ls())
graphics.off()
#package to load packages
check.packages <- function(pkg) {
new.pkg <- pkg[! (pkg %in% installed.packages()[, 'Package'])]
if(length(new.pkg))
install.packages(new.pkg, dependencies = T)
sapply(pkg, require, character.only = T)
}
check.packages(c('readxl', 'xts'))
#load excel file from file system
fairValue <- read_excel('fairValue_only.xlsx')
dataTopredict <- read_excel('inputfrom1997.xlsx')
newRownames = as.data.frame(read_excel('rownames_1995.xlsx'))
#quarters <- as.Date(as.matrix(fairValue[,1]))
fairValue <- as.data.frame(fairValue)
dataTopredict <- as.data.frame(dataTopredict)
fairValue <- xts(fairValue[,-1], order.by = as.Date.POSIXct(fairValue[,1], "%Y-%m-%d"))
#dataTopredict <- xts(dataTopredict[,-1], order.by = as.Date.POSIXct(dataTopredict[,1], "%Y-%m-%d"))
#dataTopredict <- xts(dataTopredict[,-1], order.by = as.Date.POSIXct(dataTopredict[,1], "%Y-%m-%d"))
ts_data <- ts(fairValue[61:216,], start= 1980, frequency = 4)
us_long = ts_data[,1]
sa_headline_cpi = ts_data[,2]
sa_st_policy = ts_data[,3]
sa_dGDP = ts_data[,4]
sa_long = ts_data[,5]
modRbind = cbind(us_long, sa_headline_cpi, sa_st_policy, sa_dGDP, sa_long)
##Impute missing values
check.packages('imputeTS')
#ts_data <- ts(fairValue, start = 1965, end = 2018, frequency = 4)
#ts_data <- na.seadec(ts_data, algorithm = 'interpolation')
#ts70 = ts(fairValue[21:216,], start = 1970, end = c(1997,4), frequency = 4)
"gls65 = gls(sa_long_term ~ us_long_term+sa_gdp+sa_cpi+sa_policy_rate,
correlation = corAR1())"
##Create a dataframe to store the coefficients in
##create a dataframe tp add coefficients\
coefs <- data.frame(row.names = c('intercept', 'us_long_term', 'sa_gdp', 'sa_headline_cpi', 'sa_policy_rate'))
output <- data.frame(row.names = 1:8)
outputResidualsForGLS <- data.frame(row.names = c('R2', 'RMSE', 'MAE'))
check.packages(c('modelr', 'nlme'))
i = 61
n = 0
##count to mod by 4
cunt = 0
"while ( i < 105 && n <15){
startYear = 1980+n
endYear = 2007+n
#the time series obejct
ts_data1 <- ts(fairValue[i:216,], start= startYear, end = c(endYear, 4), frequency = 4)
##The variables
us_long = ts_data1[,1]
sa_headline_cpi = ts_data1[,2]
sa_st_policy = ts_data1[,3]
sa_dGDP = ts_data1[,4]
sa_long = ts_data1[,5]
modbind = cbind(us_long, sa_headline_cpi, sa_st_policy, sa_dGDP, sa_long)
#the gls model
GLSroll = gls(sa_long ~ us_long+sa_dGDP+sa_headline_cpi+sa_st_policy,
correlation = corAR1())
summ = summary(GLSroll)
##store coefficients to a dataframe
coefs[paste(startYear,cunt,sep = '.')]  <- as.data.frame(summ$coefficients)
#print(paste('startYear',paste(startYear, cunt) ,sep = ': '))
##output the predicted variables to a dataframe
glsDATA = as.data.frame(summ$coefficients)
list_ofY <- c()
##predict 2018 - now)
for(j in 1:nrow(dataTopredict)){
us_long_term = dataTopredict[j,1]
sa_head_cpi = dataTopredict[j,2]
sa_policy = dataTopredict[j,3]
saGDP = dataTopredict[j,4]
y = glsDATA[1,1] + glsDATA[2,1]*us_long_term+ glsDATA[3,1]*saGDP+
glsDATA[4,1]*sa_head_cpi + glsDATA[5,1]*sa_policy
list_ofY <- c(list_ofY, y)
}
##1965 output
output[paste(startYear, cunt ,sep = '.')] <- list_ofY
francis <- data.frame(
R2 = rsquare(GLSroll, data=ts_data1),
RMSE = rmse(GLSroll, data=ts_data1),
MAE = mae(GLSroll, data=ts_data1)
)
outputResidualsForGLS[paste(startYear,cunt,sep = '.')] <- t(francis)
##update the while loop[]
i = i+1
cunt = cunt +1
if( cunt %% 4 == 0){
n=n+1
}
}"
## turn the thing upside down
outputResidualsForGLS = t(outputResidualsForGLS)
##zoo modbind
zoomod = zoo(modRbind)
check.packages(c('ggplot2', 'tseries', 'reshape2'))
##try roling again
rollingbeta <- rollapplyr(zoomod,
width = 112,
FUN = function(Z){
gls1 = gls(sa_long ~ us_long+sa_dGDP+sa_headline_cpi+sa_st_policy,data = as.data.frame(Z),
correlation = corAR1());
return(gls1$coef)
},
by.column=F)
##how the coefficients change over time
judas = melt(as.matrix(rollingbeta))
ggplot(judas, aes(x=Var1, y=value, fill=Var2)) + geom_bar(stat = 'identity') +theme_minimal()
i = 61
n = 0
startPos = 12
stopPos = 19
##count to mod by 4
cunt = 0
while ( i < 105 && n <15 && startPos <= 157){
startYear = 1980+n
endYear = 2007+n
#the time series obejct
ts_data1 <- ts(fairValue[i:216,], start= startYear, end = c(endYear, 4), frequency = 4)
##The variables
us_long = ts_data1[,1]
sa_headline_cpi = ts_data1[,2]
sa_st_policy = ts_data1[,3]
sa_dGDP = ts_data1[,4]
sa_long = ts_data1[,5]
modbind = cbind(us_long, sa_headline_cpi, sa_st_policy, sa_dGDP, sa_long)
#the gls model
GLSroll = gls(sa_long ~ us_long+sa_dGDP+sa_headline_cpi+sa_st_policy,
correlation = corAR1())
summ = summary(GLSroll)
##store coefficients to a dataframe
coefs[paste(startYear,cunt,sep = '.')]  <- as.data.frame(summ$coefficients)
#print(paste('startYear',paste(startYear, cunt) ,sep = ': '))
##output the predicted variables to a dataframe
glsDATA = as.data.frame(summ$coefficients)
list_ofY <- c()
##predict 2018 - now)
#print(dataTopredict[startPos,])
for(j in startPos:stopPos){
us_long_term = dataTopredict[j,1]
sa_head_cpi = dataTopredict[j,2]
sa_policy = dataTopredict[j,3]
saGDP = dataTopredict[j,4]
y = glsDATA[1,1] + glsDATA[2,1]*us_long_term+ glsDATA[3,1]*saGDP+
glsDATA[4,1]*sa_head_cpi + glsDATA[5,1]*sa_policy
list_ofY <- c(list_ofY, y)
}
startPos = startPos+4
stopPos = stopPos+4
output[paste(startYear, cunt ,sep = '.')] <- list_ofY
francis <- data.frame(
R2 = rsquare(GLSroll, data=ts_data1),
RMSE = rmse(GLSroll, data=ts_data1),
MAE = mae(GLSroll, data=ts_data1)
)
outputResidualsForGLS[paste(startYear,cunt,sep = '.')] <- t(francis)
##update the while loop[]
i = i+1
cunt = cunt +1
if( cunt %% 4 == 0){
n=n+1
}
}
check.packages('plm')
##Create a dataframe to store the coefficients in
##create a dataframe tp add coefficients\
coefs1 <- data.frame(row.names = c('intercept', 'us_long_term', 'sa_gdp', 'sa_headline_cpi', 'sa_policy_rate'))
jude = pggls(sa_long ~ us_long+sa_dGDP+sa_headline_cpi+sa_st_policy, data = modbind)
jude = pggls(sa_long ~ us_long+sa_dGDP+sa_headline_cpi+sa_st_policy)
jude = pggls(sa_long ~ us_long+sa_dGDP+sa_headline_cpi+sa_st_policy, data = modbind)
View(modbind)
jude = pggls(modbind[,5] ~ modbind[,1]+modbind[,2]+modbind[,3]+modbind[,4], data = modbind)
traceback()
jude = pggls(log(sa_long) ~ log(us_long)+log(sa_dGDP)+log(sa_headline_cpi)+log(sa_st_policy), data = modbind)
jude = pggls(log(sa_long) ~ log(us_long)+log(sa_dGDP)+log(sa_headline_cpi)+log(sa_st_policy), data = modbind, model = 'pooling')
jude = pggls(log(sa_long) ~ log(us_long)+log(sa_dGDP)+log(sa_headline_cpi)+log(sa_st_policy), data = modbind, model = 'pooling', na.action = lm)
jude = pggls(log(sa_long) ~ log(us_long)+log(sa_dGDP)+log(sa_headline_cpi)+log(sa_st_policy), data = modbind, model = 'pooling', na.action = print('jub'))
jude = pggls(modbind[,5] ~ modbind[,1]+modbind[,2]+modbind[,3]+modbind[,4], data = modbind, model = 'random')
jude = pggls(modbind[,5] ~ modbind[,1]+modbind[,2]+modbind[,3]+modbind[,4], data = modbind, model = 'pooling')
traceback()
setwd("~/Documents/futuregrowth_research/thabo_environment")
install.packages("rJava")
source('~/Documents/futuregrowth_research/thabo_environment/Emerging_Markets_Research.R', echo=TRUE)
source('~/Documents/futuregrowth_research/thabo_environment/Emerging_Markets_Research.R', echo=TRUE)
source('~/Documents/futuregrowth_research/thabo_environment/Emerging_Markets_Research.R', echo=TRUE)
source('~/Documents/futuregrowth_research/thabo_environment/Emerging_Markets_Research.R', echo=TRUE)
source('~/Documents/futuregrowth_research/thabo_environment/Emerging_Markets_Research.R', echo=TRUE)
install.packages("rJava")
source('~/Documents/futuregrowth_research/thabo_environment/Emerging_Markets_Research.R', echo=TRUE)
source('~/Documents/futuregrowth_research/thabo_environment/Emerging_Markets_Research.R', echo=TRUE)
install.packages("rJava")
source('~/Documents/futuregrowth_research/thabo_environment/Emerging_Markets_Research.R', echo=TRUE)
install.packages("rJava",,"http://cran.r-project.org",type="source")
install.packages("rJava",,"http://rforge.net/",type="source")
source('~/Documents/futuregrowth_research/thabo_environment/Emerging_Markets_Research.R', echo=TRUE)
source('~/Documents/futuregrowth_research/thabo_environment/Emerging_Markets_Research.R', echo=TRUE)
source('~/Documents/futuregrowth_research/thabo_environment/Emerging_Markets_Research.R', echo=TRUE)
rm(list = ls())
graphics.off()
#package to load packages
check.packages <- function(pkg) {
new.pkg <- pkg[! (pkg %in% installed.packages()[, 'Package'])]
if(length(new.pkg))
install.packages(new.pkg, dependencies = T)
sapply(pkg, require, character.only = T)
}
"Reads an excel file"
read.excel.file <- function(nufile){
check.packages('readxl')
#data = read_excel(file)
#if(length(which(is.na(fairValue) == TRUE)) == 0) {print('jesus')}
return (read_excel(nufile))
}
"reads an excel file and converts the date column into Date indices
the output is an XTS extensible time series object
"
convertToXTS <- function(excel_file){
fileRead = read.excel.file(excel_file)
fileRead = as.data.frame(fileRead)
check.packages('xts')
fileRead <- xts(fileRead[,-1], order.by = as.Date.POSIXct(fileRead[,1], "%Y-%m-%d"))
return(fileRead)
}
"this reads an XTS objecxt to convert it to a time series object
takes in start row position, start year, and frequency
"
convertToTimeSeries <- function(xtsObject, startPos, startYear, freq ){
timeObject <- ts(xtsObject[startPos:nrow(xtsObject),], start = startYear, frequency = freq)
return (timeObject)
}
"if your data has missing values, fills in using seasonality and trend from available data "
ImputeData <- function(tsObject){
tsFile <- data.frame()
if(length(which(is.na(tsObject) == TRUE)) == 0){
tsFile = tsObject
} else {
check.packages('imputeTS')
imputed <- na.seadec(tsObject, algorithm = 'interpolation')
tsFile = imputed
}
return(tsFile)
}
glsModel <- function(data_frame, variables){
check.packages('nlme')
"data <- data.frame(row.names = 1:nrow(data_frame))
colNames <- colnames(data_frame)
for(i in 1:variables){
data[colNames[i]] <- data[,i]
}"
model <- gls(data_frame[,5] ~ data_frame[,1]+data_frame[,2]+data_frame[,3]+data_frame[,4])
return(model)
}
#quarters <- as.Date(as.matrix(fairValue[,1]))
fairValue <- convertToXTS('fairValue_only.xlsx')
setwd("~/Documents/futuregrowth_research/codebase")
#quarters <- as.Date(as.matrix(fairValue[,1]))
fairValue <- convertToXTS('fairValue_only.xlsx')
##Create a dataframe to store the coefficients in
##create a dataframe tp add coefficients\
coefs <- data.frame(row.names = c('intercept', 'us_long_term', 'sa_gdp', 'sa_headline_cpi', 'sa_policy_rate'))
output <- data.frame(row.names = 1:8)
outputResidualsForGLS <- data.frame(row.names = c('R2', 'RMSE', 'MAE'))
check.packages(c('ggplot2', 'tseries', 'reshape2', 'modelr'))
"###A PROPER WAY of writing the solution
rollRegress <- function(FUN, startPos, startYear, window, tsDATA){
tslength = nrow(tsDATA) - window
years = (tslength+1)/4
year = 0
count = 0
while(startPos < (tslength+1) && year< years+1 ){
model_data = ts(ts)
}
}"
i = 101
n = 0
##count to mod by 4
count = 0
while ( i <= 104 && n <12){
startYear = 1990+n
endYear = 2017+n
window_size = i+112
#the time series obejct
ts_data1 <- ts(fairValue[i:window_size,], start= startYear, end = c(endYear, 4), frequency = 4)
##The variables
us_long = ts_data1[,1]
sa_headline_cpi = ts_data1[,2]
sa_st_policy = ts_data1[,3]
sa_dGDP = ts_data1[,4]
sa_long = ts_data1[,5]
modbind = cbind(us_long, sa_headline_cpi, sa_st_policy, sa_dGDP, sa_long)
#the gls model
GLSroll = gls(sa_long ~ us_long+sa_dGDP+sa_headline_cpi+sa_st_policy,
correlation = corAR1())
summ = summary(GLSroll)
##store coefficients to a dataframe
coefs[paste(startYear,count,sep = '.')]  <- as.data.frame(summ$coefficients)
#print(paste('startYear',paste(startYear, cunt) ,sep = ': '))
##output the predicted variables to a dataframe
glsDATA = as.data.frame(summ$coefficients)
francis <- data.frame(
R2 = rsquare(GLSroll, data=ts_data1),
RMSE = rmse(GLSroll, data=ts_data1),
MAE = mae(GLSroll, data=ts_data1)
)
outputResidualsForGLS[paste(startYear,count,sep = '.')] <- t(francis)
##update the while loop[]
i = i+1
count = count +1
if( count %% 4 == 0){
n=n+1
}
}
rm(list = ls())
graphics.off()
check.packages <- function(pkg) {
new.pkg <- pkg[! (pkg %in% installed.packages()[, 'Package'])]
if(length(new.pkg))
install.packages(new.pkg, dependencies = T)
sapply(pkg, require, character.only = T)
}
check.packages(c('dlm','vars', 'mFilter'))
fairValue <- read_excel('fairValue_only.xlsx')
check.packages <- function(pkg) {
new.pkg <- pkg[! (pkg %in% installed.packages()[, 'Package'])]
if(length(new.pkg))
install.packages(new.pkg, dependencies = T)
sapply(pkg, require, character.only = T)
}
check.packages(c('dlm','vars', 'mFilter'))
check.packages('readxl')
fairValue <- read_excel('fairValue_only.xlsx')
quarters <- as.Date(as.matrix(fairValue[,1]))
fairValue <- as.data.frame(fairValue)
#zoo (xts)
check.packages('xts')
fairValue <- xts(fairValue[,-1], order.by = as.Date.POSIXct(fairValue[,1], "%Y-%m-%d"))
##convert to time series object
##112 items start in 1987
check.packages('imputeTS')
ts_data <- ts(fairValue, start = 1965, end = c(1991,4) , frequency = 4)
ts_data <- na.seadec(ts_data, algorithm = 'interpolation')
##all variables
us_long_term = ts_data[,1]
sa_cpi = ts_data[,2]
sa_policy_rate = ts_data[,3]
sa_gdp = ts_data[,4]
sa_long_term = ts_data[,5]
##visualisa
plot.ts(cbind(us_long_term, sa_cpi, sa_policy_rate, sa_gdp, sa_long_term))
##check for serial correllation
#devtools::install_github("KevinKotze/tsm")
check.packages('tsm')
##check for serial correllation
devtools::install_github("KevinKotze/tsm")
##check for serial correllation
#devtools::install_github("KevinKotze/tsm")
check.packages('tsm')
us = ac(us_long_term, main='US long term')
cpi = ac(sa_cpi, main='Sa CPI')
policy_rate = ac(sa_policy_rate, main='Sa policy rate')
gdp.acf = ac(sa_gdp, main='GDP')
sa_long = ac(sa_long_term, main='SA long term')
check.packages(c('tseries', 'lmtest', 'orcutt'))
##unit roots
adf.test(us_long_term)
adf.test(sa_cpi)
adf.test(sa_policy_rate)
adf.test(sa_gdp)
adf.test(sa_long_term)
##first difference
##differentiate
us_long_diff = diff(us_long_term,1)
sa_cpi_diff = diff(sa_cpi,1)
sa_policy_diff = diff(sa_policy_rate,1)
sa_gdp_diff = diff(sa_gdp,1)
sa_long_diff = diff(sa_long_term,1)
check.packages('forecast')
modbind= cbind(sa_long_term, us_long_term, sa_cpi, sa_policy_rate, sa_gdp)
modstat = cbind(sa_long_diff, us_long_diff, sa_cpi_diff, sa_policy_diff, sa_gdp_diff)
##plot next to each otehr
check.packages('ggplot2')
check.packages('caret')
check.packages('np')
#modfit
modfit <- lm(sa_long_term ~ sa_cpi+sa_gdp+sa_policy_rate+us_long_term)
modfitDiff <- lm(sa_long_diff ~ sa_cpi_diff+sa_gdp_diff+sa_policy_diff+us_long_diff, data = modstat)
summary(modfitDiff)
summary(modfit)
###fitted
autoplot(modfit[,'sa_long_term'], series="Data") +
autolayer(fitted(modfitDiff), series="Fitted") +
xlab("Year") + ylab("") +
ggtitle("fair value mode") +
guides(colour=guide_legend(title=" "))
##evaluate teh residuals
checkresiduals(modfit)
checkresiduals(modfitDiff)
check.packages('dynlm')
install.packages("rJava")
setwd("~/Documents/futuregrowth_research/thabo_environment")
##then type main() in the console
if('openxlsx' %in% (.packages())){
detach('package:openxlsx', unload = T)
}
#lapply(packages, require, character.only = T)
check.packages <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c('readxl','rJava', 'xts','container', 'dint', 'vars', 'astsa', 'quantmod', 'TSclust',
'forecast', 'imputeTS', 'tseries', 'TTR', 'ggplot2', 'reshape2', 'leaps', 'pracma',
'broom', 'xlsx', 'lmtest', 'tibble', 'outreg')
check.packages(packages)
source('~/Documents/futuregrowth_research/thabo_environment/Emerging_Markets_Research.R', echo=TRUE)
source('~/Documents/futuregrowth_research/thabo_environment/Emerging_Markets_Research.R', echo=TRUE)
