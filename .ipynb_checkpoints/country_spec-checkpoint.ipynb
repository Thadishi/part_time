{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"utils.install_packages('vars')\\nutils.install_packages('dtwclust')\\nutils.install_packages('dtw')\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import xlrd\n",
    "import xlwt\n",
    "import xlsxwriter\n",
    "from pylab import rcParams\n",
    "\n",
    "\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects.packages as rpackages\n",
    "utils = importr('utils')\n",
    "'''utils.install_packages('vars')\n",
    "utils.install_packages('dtwclust')\n",
    "utils.install_packages('dtw')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read countries from the excel sheet, remove the first column name because it is not a country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiveYearCDS = pd.read_excel('EM_Risk_Monitor.xlsx', sheet_name='fiveYearCDS')\n",
    "fiveYearCDS.fillna(fiveYearCDS.mean(), inplace=True)\n",
    "countries =[]\n",
    "\n",
    "for names in fiveYearCDS:\n",
    "    countries.append(names)\n",
    "del countries[0]\n",
    "\n",
    "fiveYearCDS.to_csv('fiveYearCDS.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = fiveYearCDS['quarter']\n",
    "time_df = pd.DataFrame({'quarter': timeline})\n",
    "\n",
    "#for R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fiveYearCDS.to_csv('fiveYearCDS.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.4\n"
     ]
    }
   ],
   "source": [
    "import rpy2\n",
    "print(rpy2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the excel for variables and for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_names = pd.read_excel('EM_Risk_Monitor.xlsx', sheet_name=None)\n",
    "variables = [var for var in sheet_names]\n",
    "emerging = {state: pd.DataFrame(columns=variables) for state in countries}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map data by country, instead of by variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emerging['Argentina']['fiveYearCDS'] = sheet_names['fiveYearCDS']['Argentina']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in variables:\n",
    "    for j in countries:\n",
    "        emerging[j][i] = sheet_names[i][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fill in non existant items, impute values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrong way of filling in missing values - do it for completeness\n",
    "for key in emerging:\n",
    "    emerging[key].fillna(emerging[key].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add quarters and convert it to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in countries:\\n    emerging[i]['quarter'] = timeline\\n    \\nfor g in countries:\\n    emerging[g].quarter = pd.to_datetime(emerging[g].quarter)\\n    emerging[g].set_index('quarter', inplace=True)\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiveYearCDS.quarter = pd.to_datetime(fiveYearCDS.quarter)\n",
    "fiveYearCDS.set_index('quarter', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "'''for i in countries:\n",
    "    emerging[i]['quarter'] = timeline\n",
    "    \n",
    "for g in countries:\n",
    "    emerging[g].quarter = pd.to_datetime(emerging[g].quarter)\n",
    "    emerging[g].set_index('quarter', inplace=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize and standardize\n",
    "normalized ={count: pd.DataFrame(columns=variables) for count in countries}\n",
    "standardized = {count: pd.DataFrame(columns=variables) for count in countries}\n",
    "\n",
    "for state in countries:\n",
    "    normalized[state] = (emerging[state] - emerging[state].mean())/(emerging[state].max() - emerging[state].min())\n",
    "    standardized[state] = (emerging[state] - emerging[state].mean())/emerging[state].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import detrend\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in standardized:\n",
    "    #print(copy_emerging[country].isnull().values.any())\n",
    "    for var in variables:\n",
    "        decomposition = sm.tsa.seasonal_decompose(standardized[country][var], model='additive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the data stationary?????>????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#difference data\n",
    "randomized = {k: (standardized[k].diff().dropna()) for k in countries}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argentina\n",
      "0.1296067408622134\n",
      "Brazil\n",
      "0.030647739067125642\n",
      "Chile\n",
      "0.018785917554376325\n",
      "Colombia\n",
      "0.0002987118253897175\n",
      "Hungary\n",
      "0.170774109458891\n",
      "India\n",
      "0.005022677542289411\n",
      "Indonesia\n",
      "0.005214061442678909\n",
      "Malaysia\n",
      "0.04732660001932463\n",
      "Mexico\n",
      "0.016172231458135705\n",
      "Peru\n",
      "0.002017854001351399\n",
      "Philippines\n",
      "0.04985242808313357\n",
      "Poland\n",
      "0.13055975233456707\n",
      "Romania\n",
      "0.1576590798955212\n",
      "Russia\n",
      "0.022677726962634193\n",
      "South Africa\n",
      "0.0756543307898478\n",
      "Thailand\n",
      "0.06179352758897618\n",
      "Turkey\n",
      "0.0027689727934344134\n",
      "Ukraine\n",
      "0.002643474214204346\n"
     ]
    }
   ],
   "source": [
    "#testing for stationarity\n",
    "#testing for stationary for all the countries\n",
    "import statsmodels.tsa.stattools as ts\n",
    "\n",
    "for i in countries:\n",
    "    print(i)\n",
    "    adResult = ts.adfuller(standardized[i]['fiveYearCDS'])\n",
    "    print(adResult[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from statsmodels.graphics.tsaplots import plot_acf\\nfor key in variables:\\n    plot_acf(randomized['South Africa'][key])\\n    plt.title(key)\\n    plt.show()\\n    #print(key)\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#autocorrelation without first differenplot\n",
    "#corellation plot\n",
    "#autocorellation for south africa\n",
    "'''from statsmodels.graphics.tsaplots import plot_acf\n",
    "for key in variables:\n",
    "    plot_acf(randomized['South Africa'][key])\n",
    "    plt.title(key)\n",
    "    plt.show()\n",
    "    #print(key)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation relationship amongst variables per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for state in randomized:\\n    corre = randomized[state].diff().corr()\\n    plt.figure(figsize=(12,10))\\n    plt.title(state)\\n    plt.grid()\\n    sns.heatmap(corre[(corre >=0.5) | (corre <= -0.4)],\\n           cmap='viridis', vmax=1.0, vmin=-1.0, linewidth=0.1,\\n           annot=True, annot_kws={'size':8}, square=True);\\n    plt.show()\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "'''for state in randomized:\n",
    "    corre = randomized[state].diff().corr()\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.title(state)\n",
    "    plt.grid()\n",
    "    sns.heatmap(corre[(corre >=0.5) | (corre <= -0.4)],\n",
    "           cmap='viridis', vmax=1.0, vmin=-1.0, linewidth=0.1,\n",
    "           annot=True, annot_kws={'size':8}, square=True);\n",
    "    plt.show()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remvoe the NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IS there a corrrelation for some of the variables?\n",
    "Are some of the variables strongly correlatted?\n",
    "are there countries that Are affected more by certain variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#g = sns.pairplot(random_2['Russia'][variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model selection.\n",
    "WHat kind of model to use for the estimation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA is a model that is generally used initially because it works with most of time series data, and thus doesn't realy discriminate based on specific assumptions except for stationarity.\n",
    "\n",
    "So the following is an arima model selection for CDS and time\n",
    "run the model on all CDS data\n",
    "choose the one with the smallest AIC - the smaller AIC generally tends to mean a better model.\n",
    "\n",
    "so i made a loop to automatically choose the smallest aic and then fit that model.\n",
    "Then I ran model diagnostics to test for normality, proof of stationarity and to see if I can trust potential predictions from this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Which ARIMA, why ARIMA\n",
    "#p,d,g account for seasonality, trend and noise\n",
    "p = d = g = range(0,2)\n",
    "pdg = list(itertools.product(p,d,g))\n",
    "seasonal_pdg = [(x[0], x[1], x[2], 4) for x in list(itertools.product(p,d,g))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best set of parameters that yield the best performance for a model.\n",
    "\n",
    "CDS = {k: {} for k in countries}\n",
    "\n",
    "for country in countries:\n",
    "    param_AIC ={}\n",
    "    AIC=[]\n",
    "    for param in pdg:\n",
    "        for param_seasonal in seasonal_pdg:\n",
    "            #differenced = standardized[country].diff().dropna()\n",
    "            mod = sm.tsa.statespace.SARIMAX(standardized[country]['fiveYearCDS'],order=param,\n",
    "                                           seasonal_order=param_seasonal,\n",
    "                                           enforce_stationarity=False,\n",
    "                                           enforce_invertibility=False)\n",
    "            results = mod.fit()\n",
    "            rounded=round(results.aic,2)\n",
    "            AIC.append(rounded)\n",
    "            param_AIC[rounded] = [param, param_seasonal]\n",
    "        CDS[country] = param_AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the arima models\n",
    "count_results = {}\n",
    "for state in CDS:\n",
    "    tiny = min(CDS[state])\n",
    "    #differenced = standardized[state].diff().dropna()\n",
    "    model = sm.tsa.statespace.SARIMAX(standardized[state]['fiveYearCDS'],\n",
    "                                      order = (CDS[state][tiny][0][0], CDS[state][tiny][0][1], CDS[state][tiny][0][2]),\n",
    "                                      seasonal_order = (CDS[state][tiny][1][0], CDS[state][tiny][1][1],\n",
    "                                                       CDS[state][tiny][1][2], CDS[state][tiny][1][3]),\n",
    "                                      enforce_stationarity=False,\n",
    "                                      enforce_invertibility=False)\n",
    "    results = model.fit()\n",
    "    \n",
    "    count_results[state] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for state in count_results:\\n    print(state)\\n    #print(count_results[state].summary())\\n    #print(count_results[state].test_serial_correlation(None, None))\\n    count_results[state].plot_diagnostics(figsize=(16,8))\\n    plt.title(state)\\n    plt.show()'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#is it well fitted in the arima?\n",
    "#This is diagnostic for the arima results\n",
    "\n",
    "'''for state in count_results:\n",
    "    print(state)\n",
    "    #print(count_results[state].summary())\n",
    "    #print(count_results[state].test_serial_correlation(None, None))\n",
    "    count_results[state].plot_diagnostics(figsize=(16,8))\n",
    "    plt.title(state)\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Trying to predict the next 3 quarters\n",
    "##prediction for the next 3 months\n",
    "\n",
    "predicted ={}\n",
    "\n",
    "\n",
    "for region in count_results:\n",
    "    pred = count_results[region].predict(start=pd.to_datetime('2017-03-31'), end=pd.to_datetime('2018-12-31'), dynamic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardized[state] = (emerging[state] - emerging[state].mean())/emerging[state].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argentina\n",
      "Brazil\n",
      "Chile\n",
      "Colombia\n",
      "Hungary\n",
      "India\n",
      "Indonesia\n",
      "Malaysia\n",
      "Mexico\n",
      "Peru\n",
      "Philippines\n",
      "Poland\n",
      "Romania\n",
      "Russia\n",
      "South Africa\n",
      "Thailand\n",
      "Turkey\n",
      "Ukraine\n"
     ]
    }
   ],
   "source": [
    "#Continue with model selection\n",
    "#but first let's do regression love\n",
    "\n",
    "from sklearn import linear_model\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "\n",
    "for count in countries:\n",
    "    print(count)\n",
    "    #del emerging[count]['fiveYearCDS']\n",
    "    lm = linear_model.LinearRegression()\n",
    "    X = emerging[count]\n",
    "    Y = fiveYearCDS[count]\n",
    "    #model = sm.OLS(Y,X).fit()\n",
    "    mod = lm.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_d = [(1,0), (0,1), (1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following has a matrix problem, and I cannot download the package fromt the site because anaconda is blocked on our website.\n",
    "\n",
    "so we going to try this again when anaconda.com issue has been fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Va_All = {k: {} for k in countries}\\nfor state in countries:\\n    param_AIC={}\\n    AIC=[]\\n    for param in p_d:\\n        mode = sm.tsa.VARMAX(emerging[state][[variables[0], variables[1], variables[2], variables[3], variables[4], variables[5],\\n                                                   variables[6], variables[7], variables[8], variables[9], variables[10], variables[11],\\n                                               variables[12], variables[13], variables[14], variables[15], variables[16], variables[17],\\n                                               variables[18], variables[19], variables[20], variables[21], variables[22], variables[23]]],\\n                             order=param,\\n                             enforce_stationarity=False,\\n                            enforce_invertibility=False)\\n        outcome = mode.fit()\\n        rounded=round(outcome.aic,2)\\n        param_AIC[rounded] = param\\n    Va_All[state] = param_AIC'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''Va_All = {k: {} for k in countries}\n",
    "for state in countries:\n",
    "    param_AIC={}\n",
    "    AIC=[]\n",
    "    for param in p_d:\n",
    "        mode = sm.tsa.VARMAX(emerging[state][[variables[0], variables[1], variables[2], variables[3], variables[4], variables[5],\n",
    "                                                   variables[6], variables[7], variables[8], variables[9], variables[10], variables[11],\n",
    "                                               variables[12], variables[13], variables[14], variables[15], variables[16], variables[17],\n",
    "                                               variables[18], variables[19], variables[20], variables[21], variables[22], variables[23]]],\n",
    "                             order=param,\n",
    "                             enforce_stationarity=False,\n",
    "                            enforce_invertibility=False)\n",
    "        outcome = mode.fit()\n",
    "        rounded=round(outcome.aic,2)\n",
    "        param_AIC[rounded] = param\n",
    "    Va_All[state] = param_AIC'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model = sm.tsa.VARMAX(standardized['South Africa'][[variables[0], variables[1], variables[2], variables[3], variables[4], variables[5],\\n                                                   variables[6], variables[7], variables[8], variables[9], variables[10], variables[11]]], order=(1,0),\\n                     enforce_stationarity=False,\\n                     enforce_invertibility=False)\\n\\nfitting = model.fit(maxiter=1000, disp=False)\\n#fitting = model.fit()\\nfitting.summary()\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = sm.tsa.VARMAX(standardized['South Africa'][[variables[0], variables[1], variables[2], variables[3], variables[4], variables[5],\n",
    "                                                   variables[6], variables[7], variables[8], variables[9], variables[10], variables[11]]], order=(1,0),\n",
    "                     enforce_stationarity=False,\n",
    "                     enforce_invertibility=False)\n",
    "\n",
    "fitting = model.fit(maxiter=1000, disp=False)\n",
    "#fitting = model.fit()\n",
    "fitting.summary()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Time series classification.\n",
    "#Dynamic TIme Warping\n",
    "import math\n",
    "def DTWDistance(s1, s2,w):\n",
    "    DTW={}\n",
    "\n",
    "    w = max(w, abs(len(s1)-len(s2)))\n",
    "\n",
    "    for i in range(-1,len(s1)):\n",
    "        for j in range(-1,len(s2)):\n",
    "            DTW[(i, j)] = float('inf')\n",
    "    DTW[(-1, -1)] = 0\n",
    "\n",
    "    for i in range(len(s1)):\n",
    "        for j in range(max(0, i-w), min(len(s2), i+w)):\n",
    "            dist= (s1[i]-s2[j])**2\n",
    "            DTW[(i, j)] = dist + min(DTW[(i-1, j)],DTW[(i, j-1)], DTW[(i-1, j-1)])\n",
    "\n",
    "    return math.sqrt(DTW[len(s1)-1, len(s2)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##split data into training and testing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(standardized['South Africa'], test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apparently faster than dynamic time warping\n",
    "\n",
    "def LB_keogh(colum1, colum2, r):\n",
    "    LB_sum =0\n",
    "    \n",
    "    for ind, i in enumerate(colum1):\n",
    "        lower_bound = min(colum2[(ind-r if ind-r >=0 else 0): (ind+r)])\n",
    "        upper_bound = max(colum2[(ind-r if ind-r >=0 else 0): (ind+r)])\n",
    "        \n",
    "        if i>upper_bound:\n",
    "            LB_sum = LB_sum+(i-upper_bound)**2\n",
    "        elif i<lower_bound:\n",
    "            LB_sum=LB_sum+(i+lower_bound)**2\n",
    "            \n",
    "    return math.sqrt(LB_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def knn(train, test, w):\\n    preds =[]\\n    \\n    for ind, i in enumerate(test):\\n        min_dist=float('inf')\\n        closest_seq=[]\\n        \\n        for j in train:\\n            if LB_keogh(i[:-1],j[:-1],5) <min_dist:\\n                dist=DTWdistance(i[:-1],j[:-1],w)\\n                if dist<min_dist:\\n                    min_dist = dist\\n                    closest_seq = j\\n        preds.append(closest_seq[-1])\\n    return classification_report[test[:,-1],preds]\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "'''def knn(train, test, w):\n",
    "    preds =[]\n",
    "    \n",
    "    for ind, i in enumerate(test):\n",
    "        min_dist=float('inf')\n",
    "        closest_seq=[]\n",
    "        \n",
    "        for j in train:\n",
    "            if LB_keogh(i[:-1],j[:-1],5) <min_dist:\n",
    "                dist=DTWdistance(i[:-1],j[:-1],w)\n",
    "                if dist<min_dist:\n",
    "                    min_dist = dist\n",
    "                    closest_seq = j\n",
    "        preds.append(closest_seq[-1])\n",
    "    return classification_report[test[:,-1],preds]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k_means clustering\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def k_means_clust(data,num_clust,num_iter,w=5):\n",
    "    #how does one solve this problem?\n",
    "    centroids=random.sample(list(data),num_clust)\n",
    "    counter=0\n",
    "    for n in range(num_iter):\n",
    "        counter+=1\n",
    "        print(counter)\n",
    "        assignments={}\n",
    "        #assign data points to clusters\n",
    "        for ind,i in enumerate(data):\n",
    "            min_dist=float('inf')\n",
    "            closest_clust=None\n",
    "            for c_ind,j in enumerate(centroids):\n",
    "                if LB_Keogh(i,j,5)<min_dist:\n",
    "                    cur_dist=DTWDistance(i,j,w)\n",
    "                    if cur_dist<min_dist:\n",
    "                        min_dist=cur_dist\n",
    "                        closest_clust=c_ind\n",
    "            if closest_clust in assignments:\n",
    "                assignments[closest_clust].append(ind)\n",
    "            else:\n",
    "                assignments[closest_clust]=[]\n",
    "\n",
    "        #recalculate centroids of clusters\n",
    "        for key in assignments:\n",
    "            clust_sum=0\n",
    "            for k in assignments[key]:\n",
    "                clust_sum=clust_sum+data[k]\n",
    "            centroids[key]=[m/len(assignments[key]) for m in clust_sum]\n",
    "\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "judes =randomized['South Africa'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'centroids = k_means_clust(judes,4,10,5)\\n\\nfor i in centroids:\\n    plt.plot(i)\\nplt.show()'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''centroids = k_means_clust(judes,4,10,5)\n",
    "\n",
    "for i in centroids:\n",
    "    plt.plot(i)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Find which countries ahve similiar cluster for CDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import k_means\n",
    "import scipy.cluster.hierarchy as sch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = AgglomerativeClustering(n_clusters=5, linkage='complete' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2],[1,4],[1,0],\n",
    "             [4,2],[4,4],[4,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa = randomized['South Africa'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgglomerativeClustering(affinity='euclidean', compute_full_tree='auto',\n",
       "            connectivity=None, linkage='complete', memory=None,\n",
       "            n_clusters=5,\n",
       "            pooling_func=<function mean at 0x0000003C9FB3C0D0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering.fit(africa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have imported RPy2 for things I am unable to do in python that I can do in R.\n",
    "\n",
    "This will simplify the framework because R will be called within Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects.packages as rpackages\n",
    "utils = importr('utils')\n",
    "base = importr('base')\n",
    "\n",
    "var = importr('vars')\n",
    "dtwclust = importr('dtwclust')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils.install_packages('quantmod')\n",
    "quantmod = importr('quantmod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TSclust = importr('TSclust')\n",
    "#pandas data frame to R datafram\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in standardized:\n",
    "    standardized[i].to_csv(\"Countries/\"+i+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
